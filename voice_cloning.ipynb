{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a98056",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c1b572",
   "metadata": {},
   "source": [
    "## Splitting Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a5ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to your large audio file\n",
    "audio_path = \"audio.wav\" # 1 hour length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802884b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the length of each clip in milliseconds (20 seconds in this case)\n",
    "clip_length = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f758c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an AudioSegment object from the audio file\n",
    "audio = AudioSegment.from_file(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ea4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total length of the audio file in milliseconds\n",
    "audio_length = len(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15bdfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of clips we need to create\n",
    "num_clips = int(audio_length/clip_length) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c798d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory to store the clips\n",
    "output_dir = \"Audio\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f500d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the audio file and extract each clip\n",
    "for i in range(num_clips):\n",
    "    # calculate the start and end time for the clip\n",
    "    start_time = i * clip_length\n",
    "    end_time = min((i+1) * clip_length, audio_length)\n",
    "    \n",
    "    # extract the clip\n",
    "    clip = audio[start_time:end_time]\n",
    "    \n",
    "    # save the clip to a file\n",
    "    clip.export(os.path.join(output_dir, f\"voice_{i}.wav\"), format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f443e7",
   "metadata": {},
   "source": [
    "## Audio Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required code libraries\n",
    "!pip install git+https://github.com/openai/whisper.git \n",
    "!sudo apt update && sudo apt install ffmpeg\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4655ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import time\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e7b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = whisper.load_model(\"tiny.en\")\n",
    "# model = whisper.load_model(\"base.en\")   \n",
    "# model = whisper.load_model(\"small.en\")\n",
    "model = whisper.load_model(\"medium.en\")\n",
    "# model = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow access to your Google Drive and add new folders\n",
    "\n",
    "# Connect Google Drive \n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259be0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create the WhisperAudio files if they don't exist.\n",
    "folders =  [\"WhisperAudio/\", \"WhisperAudio/ProcessedAudio/\", \"WhisperAudio/TextFiles/\"]\n",
    "\n",
    "for folder in folders:\n",
    "    path = \"/content/drive/MyDrive/\" + folder\n",
    "    # Create the folder if it does not exist\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6478f03e",
   "metadata": {},
   "source": [
    "Upload any audio files you want transcribed in the \"WhisperAudio\" folder in your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9075fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the audio files are in a folder called \"WhisperAudio\" in the root of the drive\n",
    "audio_folder = \"/content/drive/MyDrive/WhisperAudio/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dcfebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the file paths and names in the folder\n",
    "import os\n",
    "audio_files = []\n",
    "audio_names = []\n",
    "for file in os.listdir(audio_folder):\n",
    "    if file.endswith(\".wav\") or file.endswith(\".mp3\"):\n",
    "        audio_files.append(audio_folder + file)\n",
    "        audio_names.append(file)\n",
    "        \n",
    "for f in audio_files:    \n",
    "    print(f)\n",
    "    \n",
    "if len(audio_files) == 0:\n",
    "    print(\"You have no files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the audio files, split each audio file based on pauses in speech then transcribe them with Whisper.\n",
    "for i, file in enumerate(audio_files): # For each audio file\n",
    "    print(f\"Processing {audio_names[i]}...\")\n",
    "    # Load the audio file and convert it to 16 kHz mono\n",
    "    audio, sr = librosa.load(file, sr=16000, mono=True)\n",
    "    # Detect pauses and split the audio. We use a threshold of -30 dB and a minimum pause length of 0.5 seconds.\n",
    "    pauses = librosa.effects.split(audio, top_db=30, frame_length=2048, hop_length=128)\n",
    "    # Transcribe each segment and concatenate the results\n",
    "    transcription = \"\"\n",
    "    for start, end in pauses: # For each segment\n",
    "        segment = audio[start:end]\n",
    "        # Save the segment as a temporary wav file\n",
    "        temp_file = \"temp.wav\"\n",
    "        sf.write(temp_file, segment, sr, subtype='PCM_16')\n",
    "        if os.path.getsize(temp_file) > 10000:\n",
    "            # Transcribe the segment with Whisper\n",
    "            result = model.transcribe(temp_file)\n",
    "            text = result[\"text\"].lstrip()\n",
    "            # Append the text to the transcription\n",
    "            print(len(transcription.split(\" \")), \"words processed\")\n",
    "            transcription += text.strip() + \" \"\n",
    "            # Delete the temporary file\n",
    "            os.remove(temp_file)\n",
    "    # Print the transcription\n",
    "    print(f\"Transcription of {audio_names[i]}:\\n\")\n",
    "    print(transcription)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Convert the spaces between sections into paragraph breaks and \n",
    "    # save the transcription as a txt document in the same folder as MyAudio.\n",
    "    \n",
    "    # Replace multiple spaces with newlines\n",
    "    transcription = re.sub(r\"\\s\\s+\", \"\\n\\n\", transcription)\n",
    "    # Create the text file name\n",
    "    text_file = audio_folder + \"/TextFiles/\" + audio_names[i][:-4] + \".txt\"\n",
    "    # Write the transcription to the text file\n",
    "    with open(text_file, \"w\") as f:\n",
    "        f.write(transcription)\n",
    "    print(f\"Saved transcription as {text_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936fbab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the audio files to \"/content/drive/MyDrive/WhisperAudio/Processed\"\n",
    "import shutil\n",
    "processed_folder = \"/content/drive/MyDrive/WhisperAudio/ProcessedAudio/\"\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(processed_folder):\n",
    "    os.mkdir(processed_folder\n",
    " \n",
    "# Move each audio file to the processed folder\n",
    "for file in audio_files:\n",
    "    shutil.move(file, processed_folder + os.path.basename(file))\n",
    "    print(f\"Moved {file} to {processed_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7675ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories to the audio samples, test files and where txt file will be stored\n",
    "audio_folder = \"/content/drive/MyDrive/WhisperAudio/wavs/\"\n",
    "txt_folder = \"/content/drive/MyDrive/WhisperAudio/TextFiles\"\n",
    "metadata_file = \"/content/drive/MyDrive/WhisperAudio/metadata.txt\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
